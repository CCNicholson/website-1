---
title: Categorical Data Analysis
author: ''
date: '2018-02-07'
slug: cda
---



<p>This set of lecture notes uses data on incoming emails for the first three months of 2012 for David Diez’s (An Open Intro Statistics Textbook author) Gmail Account, early months of 2012. All personally identifiable information has been removed.</p>
<pre class="r"><code>email &lt;- read.delim(&quot;https://norcalbiostat.netlify.com/data/email.txt&quot;, header=TRUE, sep=&quot;\t&quot;)
email &lt;- email %&gt;% mutate(hasnum = ifelse(number %in% c(&quot;big&quot;, &quot;small&quot;), 1, 0))</code></pre>
<p>Two categorical variables of current interest are</p>
<ul>
<li><code>spam</code> (0/1 binary indicator if a an email is flagged as spam). Converted into a Ham/Spam factor variable.</li>
<li><code>number</code> categorical variable describing the size of the numbers contained in the email.
<ul>
<li><code>none</code>: No numbers</li>
<li><code>small</code>: Only values under 1 million</li>
<li><code>big</code>: A value of 1 million or more</li>
</ul></li>
<li><code>hasnum</code>: 0/1 binary indicator for if the email contains any sized number</li>
</ul>
<div id="difference-of-two-proportions" class="section level1">
<h1>Difference of two proportions</h1>
<p>L et’s review comparisons of proportions in two independent samples.</p>
<p><strong>Ex</strong>: Comparison of proportions of head injuries sustained in auto accidents by passengers wearing seat belts to those not wearing seat belts. You may have already guessed the form of the estimate: <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>.</p>
<p>We are not going to go in depth into the calculations for the test statistic for a test of the difference in proportions. The OpenIntro textbook explains the assumptions and equations very well. Instead we are going to see how to use R to perform these calculations for us.</p>
<p>Since the sample proportion can be calculated as the mean of a binary indicator variable, we can use the same <code>t.test</code> function in R to conduct a hypothesis test and create a confidence interval.</p>
<div id="example-1-do-numbers-in-emails-affect-rate-of-spam-case-level-data" class="section level3">
<h3>Example 1: Do numbers in emails affect rate of spam? (Case level data)</h3>
<p>If we look at the rate of spam for emails with and without numbers, we see that 6% of emails with numbers are flagged as spam compared to 27% of emails without numbers are flagged as spam.</p>
<pre class="r"><code>email %&gt;% group_by(hasnum) %&gt;% summarize(p.spam=round(mean(spam),2))</code></pre>
<pre><code>## # A tibble: 2 x 2
##   hasnum p.spam
##    &lt;dbl&gt;  &lt;dbl&gt;
## 1      0   0.27
## 2      1   0.06</code></pre>
<p>This is such a large difference that we don’t really <em>need</em> a statistical test to tell us that this difference is significant. But we will do so anyhow for examples sake.</p>
<ol style="list-style-type: decimal">
<li><strong>State the research question:</strong> Are emails that contain numbers more likely to be spam?</li>
<li><p><strong>Define your parameters:</strong><br />
Let <span class="math inline">\(p_{nonum}\)</span> be the proportion of emails <em>without</em> numbers that are flagged as spam.<br />
Let <span class="math inline">\(p_{hasnum}\)</span> be the proportion of emails <em>with</em> numbers that are flagged as spam.</p></li>
<li><p><strong>Set up your statistical hypothesis:</strong><br />
<span class="math inline">\(H_{0}: p_{nonum} = p_{hasnum}\)</span><br />
<span class="math inline">\(H_{A}: p_{nonum} \neq p_{hasnum}\)</span></p></li>
<li><p><strong>Check assumptions:</strong> Use the pooled proportion <span class="math inline">\(\hat{p}\)</span> to check the success-failure condition.</p></li>
</ol>
<pre class="r"><code>p.hat &lt;- mean(email$spam)
p.hat</code></pre>
<pre><code>## [1] 0.09359857</code></pre>
<ul>
<li><span class="math inline">\(\hat{p}*n_{nonum}\)</span> = <code>p.hat * sum(email$hasnum==0)</code> = 51.3856159</li>
<li><span class="math inline">\(\hat{p}*n_{hasnum}\)</span> = <code>p.hat * sum(email$hasnum==1)</code> = 315.6143841</li>
<li><span class="math inline">\((1-\hat{p})*n_{nonum}\)</span> = <code>(1-p.hat)* sum(email$hasnum==0)</code> = 497.6143841</li>
<li><span class="math inline">\((1-\hat{p})*n_{hasnum}\)</span> = <code>(1-p.hat)* sum(email$hasnum==1)</code> = 3056.3856159</li>
</ul>
<p>The success-failure condition is satisfied since all values are at least 10, and we can safely apply the normal model.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Test the hypothesis</strong> by calculating a test statistic and corresponding p-value. Interpret the results in context of the problem.</li>
</ol>
<pre class="r"><code>t.test(spam~hasnum, data=email)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  spam by hasnum
## t = 10.623, df = 603.6, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.1685303 0.2449747
## sample estimates:
## mean in group 0 mean in group 1 
##      0.27140255      0.06465006</code></pre>
<p>Significantly more emails with numbers were flagged as spam compared to emails without numbers (27.1% versus 6.4% , p&lt;.0001).</p>
</div>
<div id="example-2-are-mammograms-helpful-summary-numbers-only" class="section level3">
<h3>Example 2: Are mammograms helpful? (Summary numbers only)</h3>
<p>Test whether there was a difference in breast cancer deaths in the mammogram and control groups. By entering in <span class="math inline">\(x\)</span> and <span class="math inline">\(n\)</span> as vectors we can test equivalence of these two proportions. The assumptions for using the normal model for this test have been discussed in detail in the textbook.</p>
<pre class="r"><code>prop.test(x=c(500, 505), n=c(44925, 44910))</code></pre>
<pre><code>## 
##  2-sample test for equality of proportions with continuity
##  correction
## 
## data:  c(500, 505) out of c(44925, 44910)
## X-squared = 0.01748, df = 1, p-value = 0.8948
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.001512853  0.001282751
## sample estimates:
##     prop 1     prop 2 
## 0.01112966 0.01124471</code></pre>
<p>The interval for the difference in proportions covers zero and the p-value for the test is 0.894, therefore the proportion of deaths due to breast cancer are equal in both groups. There is no indication from this data that mammograms in addition to regular breast cancer screening, change the risk of death compared to just the regular screening exams alone.</p>
</div>
</div>
<div id="contingency-tables" class="section level1">
<h1>Contingency tables</h1>
<ul>
<li>Both the explanatory and the response variables are categorical (Nominal or Ordinal)</li>
<li>Tables representing all combinations of levels of explanatory and response variables</li>
<li>A.k.a Two-way tables or <em>cross-tabs</em></li>
<li>Numbers in table represent Counts of the number of cases in each cell</li>
</ul>
<pre class="r"><code>tab &lt;- table(email$spam, email$number)
tab</code></pre>
<pre><code>##    
##      big none small
##   0  495  400  2659
##   1   50  149   168</code></pre>
</div>
<div id="measures-of-association" class="section level1">
<h1>Measures of Association</h1>
<p>We will consider two measures of association in this class.</p>
<ul>
<li>Relative Risk</li>
<li>Odds Ratio</li>
</ul>
<p>These both are calculated on a 2x2 contingency table similar to the following:</p>
<pre class="r"><code>nnnn &lt;- matrix(c(&quot;$n_{11}$&quot;, &quot;$n_{12}$&quot;, &quot;$n_{1.}$&quot;, 
                 &quot;$n_{21}$&quot;, &quot;$n_{22}$&quot;, &quot;$n_{2.}$&quot;, 
                 &quot;$n_{.1}$&quot;, &quot;$n_{.2}$&quot;, &quot;$n_{..}$&quot;), nrow=3, byrow=TRUE,  
          dimnames = list(c(&quot;Exposed&quot;, &quot;Not-Exposed&quot;, &quot;Total&quot;), c(&quot;Diseased&quot;, &quot;Not-Diseased&quot;, &quot;Total&quot;)))
print(xtable(nnnn, align=&#39;cccc&#39;), type=&#39;html&#39;)</code></pre>
<!-- html table generated in R 3.4.1 by xtable 1.8-2 package -->
<!-- Wed Feb 07 09:41:33 2018 -->
<table border="1">
<tr>
<th>
</th>
<th>
Diseased
</th>
<th>
Not-Diseased
</th>
<th>
Total
</th>
</tr>
<tr>
<td align="center">
Exposed
</td>
<td align="center">
<span class="math inline">\(n_{11}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{12}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{1.}\)</span>
</td>
</tr>
<tr>
<td align="center">
Not-Exposed
</td>
<td align="center">
<span class="math inline">\(n_{21}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{22}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{2.}\)</span>
</td>
</tr>
<tr>
<td align="center">
Total
</td>
<td align="center">
<span class="math inline">\(n_{.1}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{.2}\)</span>
</td>
<td align="center">
<span class="math inline">\(n_{..}\)</span>
</td>
</tr>
</table>
<p>Sometimes the cell contents are abbreviated as:</p>
<pre class="r"><code>abcd &lt;- matrix(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), nrow=2,  
          dimnames = list(c(&quot;Exposed&quot;, &quot;Not-Exposed&quot;), c(&quot;Diseased&quot;, &quot;Not-Diseased&quot;)))
print(xtable(abcd, align=&#39;ccc&#39;), type=&#39;html&#39;)</code></pre>
<!-- html table generated in R 3.4.1 by xtable 1.8-2 package -->
<!-- Wed Feb 07 09:41:34 2018 -->
<table border="1">
<tr>
<th>
</th>
<th>
Diseased
</th>
<th>
Not-Diseased
</th>
</tr>
<tr>
<td align="center">
Exposed
</td>
<td align="center">
a
</td>
<td align="center">
c
</td>
</tr>
<tr>
<td align="center">
Not-Exposed
</td>
<td align="center">
b
</td>
<td align="center">
d
</td>
</tr>
</table>
<p><br></br></p>
<p>6 minute Marin Stats Lecture: <a href="https://www.youtube.com/watch?v=V_YNPQoAyCc" class="uri">https://www.youtube.com/watch?v=V_YNPQoAyCc</a></p>
<div id="relative-risk" class="section level2">
<h2>Relative Risk</h2>
<p>The <strong>Relative Risk (RR)</strong> or <strong>Risk Ratio</strong> is the ratio of the probability of an event occurring in an exposed group compared to the probability of an event occurring in a non-exposed group.</p>
<ul>
<li>Asymptotically approaches the OR for small probabilities.</li>
<li>Often used in cohort studies and randomized control trials.</li>
</ul>
<p>Consider sample proportions Diseases within Exposed and Non-exposed groups. <span class="math display">\[\hat{\pi}_{1} = \frac{n_{11}}{n_{1.}} \qquad \mbox{and} \qquad \hat{\pi}_{2} = \frac{n_{21}}{n_{2.}}\]</span></p>
<p>The Relative Risk is calculated as</p>
<p><span class="math display">\[RR = \frac{\hat{\pi}_{1}}{\hat{\pi}_{2}} \qquad \mbox{or} \qquad \frac{a/(a+b)}{c/(c+d)}\]</span></p>
<p>with variance <span class="math display">\[V = \frac{1-\hat{\pi}_{1}}{n_{11}} + \frac{1-\hat{\pi}_{2}}{n_{21}}\]</span></p>
</div>
<div id="odds-ratio" class="section level2">
<h2>Odds Ratio</h2>
<p>The <strong>Odds Ratio (OR)</strong> is a way to quantify how strongly the presence or absence of a characteristic affects the presence or absence of a second characteristic.</p>
<ul>
<li>Often used in case-control studies</li>
<li>The main interpretable estimate generated from logistic regression</li>
</ul>
<p>The <strong>Odds of an event</strong> is the probability it occurs divided by the probability it does not occur.</p>
<p><span class="math display">\[ odds_{1} = \frac{n_{11}/n_{1.}}{n_{12}/n_{1.}} = \frac{n_{11}}{n_{12}} \]</span> <span class="math display">\[ odds_{2} = \frac{n_{21}/n_{2.}}{n_{22}/n_{2.}} = \frac{n_{21}}{n_{22}} \]</span></p>
<p>The <strong>Odds Ratio</strong> for group 1 compared to group 2 is the ratio of the two odds written above:</p>
<p><span class="math display">\[OR = \frac{odds_{1}}{odds_{2}} = \frac{n_{11}n_{22}}{n_{12}n_{21}} \qquad \mbox{or} \qquad \frac{ad}{bc}\]</span></p>
<p>with variance <span class="math inline">\(V = n^{-1}_{11} + n^{-1}_{12} + n^{-1}_{21} + n^{-1}_{22}\)</span>.</p>
</div>
<div id="confidence-intervals" class="section level2">
<h2>Confidence Intervals</h2>
<p>Neither the Risk Ratio nor the Odds Ratio are linear functions, so a 95% CI for the population estimates are not your typical <span class="math inline">\(\hat{\theta} \pm 1.96\sqrt{Var(\hat{\theta})}\)</span>.</p>
<p>Instead they are calculated as the point estimate <span class="math inline">\(\hat{\theta}\)</span> times <span class="math inline">\(e\)</span> raised to the <span class="math inline">\(\pm 1.96\)</span> times the standard deviation of the estimate.</p>
<p><span class="math display">\[(\hat{\theta}e^{-1.96*\sqrt{V}}, \hat{\theta}e^{1.96*\sqrt{V}})\]</span></p>
<div id="example-are-emails-with-numbers-in-them-more-likely-to-be-flagged-as-spam" class="section level3">
<h3>Example: Are emails with numbers in them more likely to be flagged as spam?</h3>
<p>Reconsider the 2x2 table that compares emails flagged as spam to those containing numbers.</p>
<pre class="r"><code>table(email$hasnum, email$spam, dnn=c(&quot;Has Number&quot;, &quot;Spam&quot;))</code></pre>
<pre><code>##           Spam
## Has Number    0    1
##          0  400  149
##          1 3154  218</code></pre>
<p>Note that both the columns and rows are swapped when compared to the a/b/c/d format. For ease of interpretation I will recreate the table manually.</p>
<pre class="r"><code>tab_sn &lt;- matrix(c(149, 218, 400, 3154), nrow=2, byrow=T, 
                 dimnames = list(c(&quot;Has Num&quot;, &quot;No Num&quot;), c(&quot;Spam&quot;, &quot;Ham&quot;)))
tab_sn</code></pre>
<pre><code>##         Spam  Ham
## Has Num  149  218
## No Num   400 3154</code></pre>
<p>Now I use the <code>epi.2by2</code> function contained in the <code>epiR</code> package to calculate the Odds Ratio, the Risk Ratio, and their respective confidence intervals.</p>
<pre class="r"><code>library(epiR)
epi.2by2(tab_sn)</code></pre>
<pre><code>##              Outcome +    Outcome -      Total        Inc risk *
## Exposed +          149          218        367              40.6
## Exposed -          400         3154       3554              11.3
## Total              549         3372       3921              14.0
##                  Odds
## Exposed +       0.683
## Exposed -       0.127
## Total           0.163
## 
## Point estimates and 95 % CIs:
## -------------------------------------------------------------------
## Inc risk ratio                               3.61 (3.09, 4.21)
## Odds ratio                                   5.39 (4.27, 6.80)
## Attrib risk *                                29.34 (24.21, 34.48)
## Attrib risk in population *                  2.75 (1.24, 4.25)
## Attrib fraction in exposed (%)               72.28 (67.65, 76.24)
## Attrib fraction in population (%)            19.62 (15.83, 23.23)
## -------------------------------------------------------------------
##  X2 test statistic: 237.889 p-value: &lt; 0.001
##  Wald confidence limits
##  * Outcomes per 100 population units</code></pre>
<ul>
<li>Emails containing numbers are 3.6 (3.09, 4.21) times as likely as emails without numbers to be flagged as spam.</li>
<li>Emails containing numbers have 5.4 (4.27, 6.80) times the odds of being flagged as spam compared to emails without numbers in them.</li>
</ul>
<p>Both intervals are greater than 1, therefore the event (spam) is statistically more likely to occur in the exposed group (has num) than in the control (no num) (p&lt;.0001). The p-value for the Wald <span class="math inline">\(\chi^{2}\)</span> test is &lt;.0001.</p>
<ul>
<li>Mathematical reference for the Wald test Statistic <a href="http://www.statlect.com/Wald_test.htm" class="uri">http://www.statlect.com/Wald_test.htm</a></li>
</ul>
</div>
</div>
</div>
<div id="tests-of-association" class="section level1">
<h1>Tests of Association</h1>
<p>There are three main tests of association for <span class="math inline">\(rxc\)</span> contingency table.</p>
<ul>
<li>Test of Goodness of Fit</li>
<li>Tests of Independence</li>
<li>Test of Homogeneity</li>
</ul>
<p><strong>Notation</strong></p>
<ul>
<li><span class="math inline">\(r\)</span> is the number of rows and indexed by <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(c\)</span> is the number of columns and indexed by <span class="math inline">\(j\)</span>.</li>
</ul>
<p><br></br></p>
<div id="goodness-of-fit" class="section level2">
<h2>Goodness of Fit</h2>
<ul>
<li>OpenIntro Statistics: Chapter 6.3</li>
<li>Tests whether a set of multinomial counts is distributed according to a theoretical set of population proportions.</li>
<li>Does a set of categorical data come from a claimed distribution?</li>
<li>Are the observed frequencies consistent with theory?</li>
</ul>
<p><span class="math inline">\(H_{0}\)</span>: The data come from the claimed discrete distribution<br />
<span class="math inline">\(H_{A}\)</span>: The data to not come from the claimed discrete distribution.</p>
<p><br></br></p>
</div>
<div id="test-of-independence" class="section level2">
<h2>Test of Independence</h2>
<ul>
<li>OpenIntro Statistics: Chapter 6.4</li>
<li>Determine whether two categorical variables are associated with one another in the population
<ul>
<li>Ex. Race and smoking, or education level and political affiliation.</li>
</ul></li>
<li>Data are collected at random from a population and the two categorical variables are observed on each unit.</li>
</ul>
<p><span class="math inline">\(H_{0}: p_{ij} = p_{i.}p_{.j}\)</span><br />
<span class="math inline">\(H_{A}: p_{ij} \neq p_{i.}p_{.j}\)</span></p>
<p><br></br></p>
</div>
<div id="test-of-homogeneity" class="section level2">
<h2>Test of Homogeneity</h2>
<ul>
<li>A test of homogeneity tests whether two (or more) sets of multinomial counts come from different sets of population proportions.</li>
<li>Does two or more sub-groups of a population share the same distribution of a single categorical variable?
<ul>
<li>Ex: Do people of different races have the same proportion of smokers?</li>
<li>Ex: Do different education levels have different proportions of Democrats, Republicans, and Independents?</li>
</ul></li>
<li>Data on one characteristic is collected from randomly sampling individuals within each subroup of the second characteristic.</li>
</ul>
<p><span class="math inline">\(H_{0}:\)</span></p>
<p><span class="math display">\[p_{11} = p_{12} = \ldots = p_{1c}\]</span> <span class="math display">\[p_{21} = p_{22} = \ldots = p_{2c}\]</span> <span class="math display">\[\qquad \vdots \]</span> <span class="math display">\[ p_{r1} = p_{r2} = \ldots = p_{rc}\]</span></p>
<p><span class="math inline">\(H_{A}:\)</span> At least one of the above statements is false.</p>
<p><br></br></p>
<p>All three tests use the <strong>Pearsons’ Chi-Square</strong> test statistic.</p>
<div id="chi-squared-distribution" class="section level4">
<h4>Chi-Squared Distribution</h4>
<p>Much of categorical data analysis uses the <span class="math inline">\(\chi^{2}\)</span> distribution.</p>
<p><img src="/lec/Cat_data_analysis_files/figure-html/unnamed-chunk-13-1.png" width="480" style="display: block; margin: auto;" /></p>
<ul>
<li>The shape is controlled by a degrees of freedom parameter (df)</li>
<li>Is used in many statistical tests for categorical data.</li>
<li>Is always positive (it’s squared!)
<ul>
<li>High numbers result in low p-values</li>
</ul></li>
<li>Mathematically connected to many other distributions
<ul>
<li>Special case of the gamma distribution (One of the most commonly used statistical distributions)</li>
<li>The sample variance has a <span class="math inline">\(\chi^{2}_{n-1}\)</span> distribution.<br />
</li>
<li>The sum of <span class="math inline">\(k\)</span> independent standard normal distributions has a <span class="math inline">\(\chi^{2}_{k}\)</span> distribution.</li>
<li>The ANOVA F-statistic is the ratio of two <span class="math inline">\(\chi^{2}\)</span> distributions divided by their respective degrees of freedom.</li>
</ul></li>
</ul>
<p><br></br></p>
</div>
</div>
<div id="pearsons-chi-square" class="section level2">
<h2>Pearsons’ Chi-Square</h2>
<p>The chi-squared test statistic is the sum of the squared differences between the observed and expected values, divided by the expected value.</p>
<div id="one-way-table" class="section level3">
<h3>One way table</h3>
<p><span class="math display">\[\chi^{2} = \sum^{r}_{i=1} \frac{(O_{i}-E_{i})^2}{E_{i}}\]</span></p>
<ul>
<li><span class="math inline">\(O_{i}\)</span> observed number of type <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(E_{i}\)</span> expected number of type <span class="math inline">\(i\)</span>. Equal to <span class="math inline">\(Np_{i}\)</span> under the null hypothesis</li>
<li>N is the total sample size</li>
<li>df = r-1</li>
</ul>
</div>
<div id="two-way-tables" class="section level3">
<h3>Two way tables</h3>
<p><span class="math display">\[\chi^{2} = \sum^{r}_{i=1}\sum^{c}_{j=1} \frac{(O_{ij}-E_{ij})^2}{E_{ij}}\]</span></p>
<ul>
<li><span class="math inline">\(O_{ij}\)</span> observed number in cell <span class="math inline">\(ij\)</span></li>
<li><span class="math inline">\(E_{ij} = Np_{i.}p_{.j}\)</span> under the null hypothesis</li>
<li>N is the total sample size</li>
<li>df = (r-1)(c-1)</li>
</ul>
<p><br></br></p>
</div>
<div id="conducting-these-tests-in-r." class="section level3">
<h3>Conducting these tests in R.</h3>
<ul>
<li>Test of equal or given proportions using <code>prop.test()</code></li>
</ul>
<pre class="r"><code>prop.test(table(email$number, email$spam))</code></pre>
<pre><code>## 
##  3-sample test for equality of proportions without continuity
##  correction
## 
## data:  table(email$number, email$spam)
## X-squared = 243.51, df = 2, p-value &lt; 2.2e-16
## alternative hypothesis: two.sided
## sample estimates:
##    prop 1    prop 2    prop 3 
## 0.9082569 0.7285974 0.9405730</code></pre>
<ul>
<li>Chi-squared contingency table tests and goodness-of-fit tests using <code>chisq.test()</code>.<br />
This function can take raw data as input</li>
</ul>
<pre class="r"><code>chisq.test(email$number, email$spam)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  email$number and email$spam
## X-squared = 243.51, df = 2, p-value &lt; 2.2e-16</code></pre>
<p>or a table object.</p>
<pre class="r"><code>chisq.test(tab)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab
## X-squared = 243.51, df = 2, p-value &lt; 2.2e-16</code></pre>
</div>
<div id="prop.test-vs-chisq.test" class="section level3">
<h3>prop.test vs chisq.test()</h3>
<pre class="r"><code>pt.out &lt;- prop.test(table(email$number, email$spam))
cs.out &lt;- chisq.test(tab)</code></pre>
<ul>
<li>Same calculated test statistic and p-value</li>
</ul>
<pre class="r"><code>c(pt.out$statistic, pt.out$p.value)</code></pre>
<pre><code>##    X-squared              
## 2.435137e+02 1.323321e-53</code></pre>
<pre class="r"><code>c(cs.out$statistic, cs.out$p.value)</code></pre>
<pre><code>##    X-squared              
## 2.435137e+02 1.323321e-53</code></pre>
<ul>
<li><code>prop.test</code>
<ul>
<li>has a similar output appearance to other hypothesis tests</li>
<li>shows sample proportions of outcome within each group</li>
</ul></li>
<li><code>chisq.test</code>
<ul>
<li>stores the matricies of <span class="math inline">\(O_{ij}\)</span>, <span class="math inline">\(E_{ij}\)</span>, the residuals and standardized residuals</li>
</ul></li>
</ul>
<pre class="r"><code>cs.out$expected</code></pre>
<pre><code>##    
##           big      none     small
##   0 493.98878 497.61438 2562.3968
##   1  51.01122  51.38562  264.6032</code></pre>
</div>
<div id="mosaicplots" class="section level3">
<h3>Mosaicplots</h3>
<ul>
<li>The Pearson <span class="math inline">\(\chi^{2}\)</span> test statistic = Sum of squared residuals.</li>
<li>A shaded mosaicplot shows the magnitude of the residuals.
<ul>
<li>Blue (positive residuals) = More frequent than expected</li>
<li>Red (negative residuals) = Less frequent than expected.</li>
</ul></li>
</ul>
<pre class="r"><code>mosaicplot(tab, shade=TRUE, main=&quot;Association of spam status and number size in emails&quot;)</code></pre>
<p><img src="/lec/Cat_data_analysis_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>There are more spam emails with no numbers, fewer Ham emails with no numbers, and fewer spam emails with small numbers than would be expected if these factors were independent.</p>
<ul>
<li>More information on mosaicplots - <a href="http://www.datavis.ca/online/mosaics/about.html" class="uri">http://www.datavis.ca/online/mosaics/about.html</a></li>
</ul>
</div>
</div>
</div>
<div id="assumptions-and-extensions" class="section level1">
<h1>Assumptions and Extensions</h1>
<ul>
<li>Simple random sample</li>
<li>Adequate expected cell counts
<ul>
<li>At least 5 in all cells of a 2x2, or at least 80% of cells in a larger table.</li>
<li>NO cells with 0 cell count</li>
</ul></li>
<li>Observations are independent</li>
</ul>
<p>If one or more of these assumptions are not satisfied, other methods may still be useful.</p>
<ul>
<li>McNemar’s Test for paired or correlated data</li>
<li>Fishers exact test for when cell sizes are small (&lt;5-10)</li>
<li>Inter-rater reliability: Concordant and Discordant Pairs</li>
</ul>
</div>
